# 爬虫相关常用库

爬虫常用库有大概分别是这几种类型: 请求库,解析库,存储库和工具库

## urllib & re

python自带,请求库

```python
import urllib
import urllib.request
urllib.request.urlopen('http://www.baidu.com')
```

## requests

请求库,conda安装

```python
import requests
requests.get('http://www.baidu.com')
```

## selenium & chromedriver

驱动浏览器,conda安装

需要另外下载chromedriver,放在虚拟环境下的Scripts文件夹中

```python
from selenium import webdriver
# 此时会启动chrome进入调试
driver = webdriver.Chrome()
# 可以驱动浏览器打开网址
driver.get('http://www.baidu.com')
# 可以获取网页源码
driver.page_source
```

[PS]由于我的chrome是最新版本,没有遇到chromedriver与浏览器版本不相容的问题,以后安装时要注意此问题.

[chromedriver下载地址](http://chromedriver.storage.googleapis.com/index.html)

## phantomjs

这是个无界面浏览器,会在后台自动运行,不会像chrome那样一直跳出打开网页

下载解压到指定位置,然后将其中的bin目录加入系统环境变量中

```python
from selenium import webdriver
# 创建phantomjs对象
driver = webdriver.Phantomjs()
# 可以驱动浏览器打开网址,但是不会跳出任何窗口
driver.get('http://www.baidu.com')
# 可以获取网页源码
driver.page_source
```

## lxml

conda安装,解析库

## beautifulsoup4

conda安装,解析库,基于lxml

```python
from bs4 import BeautifulSoup
soup = BeautifulSoup('<html></html>','lxml')
```

## pyquery

语法和jquery一致

conda安装

```python
from pyquery import PyQuery as pq
doc = pq('<html></html>')
doc = pq('<html>hello</html>')
result = doc('html').text()
result  # 'hello'
```

## pymysql

conda安装

```python
import pymysql
# 建立连接
conn = pymysql.connect(host='localhost',user='root',password='root',port=3306, db='mysql')
cursor = conn.cursor()
cursor.execute('select * from db')
# 查看数据
cursor.fetchone()
```

## pymongo

conda安装

```python
import pymongo
client = pymongo.MongoClient('localhost')
db = client['newtestdb']
# 注意mongo语法 {}
# 插入数据
db['table'].insert({'name':'steve'})
# 查询数据
db['table'].find_one({'name':'steve'})
```

## redis

conda安装之后导入不成功,之后改成pip安装

```python
import redis
r = redis.Redis('localhost', 6379)
r.set('name','steve')
r.get('name')
```

## flask

conda安装

## django

conda安装